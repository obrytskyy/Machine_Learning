{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# Reading the Data\n",
    "df =  pd.read_csv('house_prices.csv',encoding='gbk',low_memory=False)#, errors='ignore')\n",
    "# Shape of the Data\n",
    "print ('DATA',df.shape)\n",
    "df.head(1)\n",
    "\n",
    "# Step 1: Remove variables with more than 50% missing data\n",
    "df = df.drop(['DOM'], axis=1)\n",
    "# Step 2: Remove observations with any missing values and with values '未知' = None\n",
    "df = df.dropna()\n",
    "df = df[df['constructionTime']!='未知']\n",
    "# Step 3: Removing the columns 'kitchens', 'bathrooms', and 'drawingRooms'\n",
    "df.drop(['kitchen', 'bathRoom', 'drawingRoom', 'url', 'id', 'Cid', 'floor', 'buildingType', 'ladderRatio'], axis=1, inplace=True)\n",
    "# Step 4: Setting the number of living rooms to be within the range of 1 to 4\n",
    "df['livingRoom'] = pd.to_numeric(df['livingRoom'], errors='coerce')\n",
    "df['livingRoom'] = df['livingRoom'].clip(lower=1, upper=4)\n",
    "df.columns\n",
    "print (\"DATA\", df.shape)\n",
    "\n",
    "# Creating 'distance' feature\n",
    "# To calculate Distance Between Two Points on Earth \n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lat1, lon1, lat2=39.916668, lon2=116.383331):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "df['distance'] = df.apply(lambda x: haversine(x['Lat'], x['Lng']), axis=1)\n",
    "df['constructionTime'] = df['constructionTime'].astype(int)\n",
    "df['age'] = 2023 - pd.to_numeric(df['constructionTime'], errors='coerce')\n",
    "# Drop the original 'constructionTime' column\n",
    "df.drop('constructionTime', axis=1, inplace=True)\n",
    "\n",
    "# Set minimum values\n",
    "min_price = 10000\n",
    "min_square = 20\n",
    "\n",
    "df['price'] = df['price'].clip(lower=min_price)\n",
    "df['square'] = df['square'].clip(lower=min_square)\n",
    "\n",
    "print ('DATA',df.shape)\n",
    "df.head(1)\n",
    "\n",
    "# 'timeTrade' feature to year base only.\n",
    "df['tradeTime'] = pd.DatetimeIndex(df['tradeTime']).year\n",
    "\n",
    "# Converting features datatype to see outliers\n",
    "df['livingRoom'] = df['livingRoom'].astype(int)\n",
    "df['tradeTime'] = df['tradeTime'].astype(int)\n",
    "df['renovationCondition'] = df['renovationCondition'].astype(int)\n",
    "df['buildingStructure'] = df['buildingStructure'].astype(int)\n",
    "df['elevator'] = df['elevator'].astype(int)\n",
    "df['fiveYearsProperty'] = df['fiveYearsProperty'].astype(int)\n",
    "df['subway'] = df['subway'].astype(int)\n",
    "df['followers']  = df['followers'].astype(int)\n",
    "df['totalPrice']  = df['totalPrice'].astype(int)\n",
    "df['elevator']  = df['elevator'].astype(int)\n",
    "df['fiveYearsProperty']  = df['fiveYearsProperty'].astype(int)\n",
    "df['subway']  = df['subway'].astype(int)\n",
    "df['age']  = df['age'].astype(int)\n",
    "\n",
    "# Reseting the index\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'],axis=1,inplace=True)\n",
    "# Now the remaining data\n",
    "print (\"DATA\", df.shape)\n",
    "df.head()\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95078e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "X = df.drop('totalPrice', axis=1)\n",
    "y = df['totalPrice']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class KerasClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self, optimizer='adam', input_shape=None):\n",
    "        self.optimizer = optimizer\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def create_model(self):\n",
    "        if self.input_shape is None:\n",
    "            raise ValueError(\"Input shape must be defined\")\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(self.input_shape,)), \n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1)  \n",
    "        ])\n",
    "        model.compile(loss='mean_squared_error', optimizer=self.optimizer)\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.input_shape is None:\n",
    "            self.input_shape = X.shape[1]\n",
    "        self.model = self.create_model()\n",
    "        self.model.fit(X, y, epochs=10, batch_size=10, verbose=1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "\n",
    "input_shape = X_train_scaled.shape[1]\n",
    "model = KerasClassifier(input_shape=input_shape)\n",
    "\n",
    "param_grid = {'optimizer': ['adam', 'sgd']}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, learning_rate=0.01, input_shape=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def create_model(self):\n",
    "        if self.input_shape is None:\n",
    "            raise ValueError(\"Input shape must be defined\")\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(self.input_shape,)), \n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1)  \n",
    "        ])\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.input_shape is None:\n",
    "            self.input_shape = X.shape[1]\n",
    "        self.model = self.create_model()\n",
    "        self.model.fit(X, y, epochs=10, batch_size=10, verbose=1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "\n",
    "input_shape = X_train_scaled.shape[1]\n",
    "my_model = KerasRegressor(input_shape=input_shape)\n",
    "\n",
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1]}\n",
    "grid = GridSearchCV(estimator=my_model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16243da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbac0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Configure early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=1e-4, \n",
    "    patience=10, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    validation_split=0.2, \n",
    "    epochs=150, \n",
    "    batch_size=32, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3066679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "from numpy import sqrt\n",
    "\n",
    "# Function to calculate RMSLE\n",
    "def rmsle(y_true, y_pred):\n",
    "    return sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating RMSLE\n",
    "test_rmsle = rmsle(y_test, y_pred)\n",
    "print('Test RMSLE:', test_rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs. Predicted Values')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
